{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP84dX0oyPjqxd9vQIuRKTO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dharanie-shankar/Lab-Gen-AI-for-NLP/blob/main/EXL_Gen_AI_for_NLP_Lab_submission_Dharanie_Shankar_R.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab Questions - 2024-05-24\n",
        "##### Submitted by,\n",
        "##### Dharanie Shankar R\n",
        "##### (dharanie.r@exlservice.com / dharanie.shankar@gmail.com)"
      ],
      "metadata": {
        "id": "HG-j9XFeV8qC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q1. Create a basic feedforward neural network for binary classification (use generate input using numpy random module)"
      ],
      "metadata": {
        "id": "RcoxF6wVVvMF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Step 2: Generate some random data for demonstration\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(100, 2)  # Features (2 input neurons)\n",
        "y = (X[:, 0] + X[:, 1] > 1).astype(int)  # Binary target variable\n",
        "\n",
        "## Step 3: Create a Sequential model\n",
        "first_model = Sequential()\n",
        "\n",
        "# Step 4: Add layers to the model\n",
        "first_model.add(Dense(3, input_dim=2, activation='relu'))  # Hidden layer with 3 neurons\n",
        "first_model.add(Dense(1, activation='sigmoid'))  # Output layer with 1 neuron (binary classification)"
      ],
      "metadata": {
        "id": "gaOxfnyjWHVo"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Compile the model\n",
        "first_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "PxvOWqHlV7vp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Train the model\n",
        "first_model.fit(X, y, epochs=15, batch_size=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yag84PzeWuJ-",
        "outputId": "8d595e78-1313-4b87-c133-f39e0a80edd3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "5/5 [==============================] - 3s 16ms/step - loss: 0.6730 - accuracy: 0.6600\n",
            "Epoch 2/15\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6722 - accuracy: 0.6700\n",
            "Epoch 3/15\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6717 - accuracy: 0.6700\n",
            "Epoch 4/15\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6709 - accuracy: 0.6700\n",
            "Epoch 5/15\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6702 - accuracy: 0.6600\n",
            "Epoch 6/15\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6696 - accuracy: 0.6600\n",
            "Epoch 7/15\n",
            "5/5 [==============================] - 0s 8ms/step - loss: 0.6690 - accuracy: 0.6600\n",
            "Epoch 8/15\n",
            "5/5 [==============================] - 0s 15ms/step - loss: 0.6682 - accuracy: 0.6600\n",
            "Epoch 9/15\n",
            "5/5 [==============================] - 0s 11ms/step - loss: 0.6675 - accuracy: 0.6700\n",
            "Epoch 10/15\n",
            "5/5 [==============================] - 0s 7ms/step - loss: 0.6668 - accuracy: 0.6800\n",
            "Epoch 11/15\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6661 - accuracy: 0.6700\n",
            "Epoch 12/15\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6653 - accuracy: 0.6700\n",
            "Epoch 13/15\n",
            "5/5 [==============================] - 0s 9ms/step - loss: 0.6648 - accuracy: 0.6700\n",
            "Epoch 14/15\n",
            "5/5 [==============================] - 0s 10ms/step - loss: 0.6641 - accuracy: 0.6700\n",
            "Epoch 15/15\n",
            "5/5 [==============================] - 0s 12ms/step - loss: 0.6635 - accuracy: 0.6700\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ee655b1ff10>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Evaluate the model\n",
        "loss, accuracy = first_model.evaluate(X, y)\n",
        "print(f'Loss: {loss:.4f}')\n",
        "print(f'Accuracy: {accuracy*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HyP8pwrgWwWn",
        "outputId": "cccedfcb-f9de-4f90-d302-b58cbd998011"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 1s 16ms/step - loss: 0.6631 - accuracy: 0.6600\n",
            "Loss: 0.6631\n",
            "Accuracy: 66.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rzx_v__IWyCf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q2. Create a neural network model by your own name with a random input function of shape 300*4 for Binary classification (use generate input using numpy random module)"
      ],
      "metadata": {
        "id": "uD6JBGqAXn0g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Step 2: Generate some random data for demonstration\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(300, 4)  # Features (4 input neurons)\n",
        "y = (X[:, 0] + X[:, 1] > 1).astype(int)  # Binary target variable\n",
        "\n",
        "## Step 3: Create a Sequential model of my name (Dharanie Shankar R)\n",
        "dharanie_model = Sequential()\n",
        "\n",
        "# Step 4: Add layers to the model\n",
        "dharanie_model.add(Dense(3, input_dim=4, activation='relu'))  # Hidden layer with 3 neurons\n",
        "dharanie_model.add(Dense(1, activation='sigmoid'))  # Output layer with 1 neuron (binary classification)\n",
        "\n",
        "# Step 5: Compile the model\n",
        "dharanie_model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "fc73_bkTYEEy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Train the model\n",
        "dharanie_model.fit(X, y, epochs=15, batch_size=20)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Buu7feYBZHbo",
        "outputId": "9e12b19d-3085-4426-efe5-87f63626ac71"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "15/15 [==============================] - 1s 6ms/step - loss: 0.6935 - accuracy: 0.4667\n",
            "Epoch 2/15\n",
            "15/15 [==============================] - 0s 6ms/step - loss: 0.6930 - accuracy: 0.5333\n",
            "Epoch 3/15\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6928 - accuracy: 0.5333\n",
            "Epoch 4/15\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6925 - accuracy: 0.5333\n",
            "Epoch 5/15\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6921 - accuracy: 0.5333\n",
            "Epoch 6/15\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6917 - accuracy: 0.5333\n",
            "Epoch 7/15\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6910 - accuracy: 0.5333\n",
            "Epoch 8/15\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6899 - accuracy: 0.5333\n",
            "Epoch 9/15\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6882 - accuracy: 0.5333\n",
            "Epoch 10/15\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6863 - accuracy: 0.5333\n",
            "Epoch 11/15\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6841 - accuracy: 0.5333\n",
            "Epoch 12/15\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6820 - accuracy: 0.5333\n",
            "Epoch 13/15\n",
            "15/15 [==============================] - 0s 4ms/step - loss: 0.6800 - accuracy: 0.5333\n",
            "Epoch 14/15\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6779 - accuracy: 0.5333\n",
            "Epoch 15/15\n",
            "15/15 [==============================] - 0s 3ms/step - loss: 0.6757 - accuracy: 0.5333\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ee6465619c0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Evaluate the model\n",
        "loss, accuracy = dharanie_model.evaluate(X, y)\n",
        "print(f'Loss: {loss:.4f}')\n",
        "print(f'Accuracy: {accuracy*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlxBrl7PZIcq",
        "outputId": "5144537d-05db-4b60-ef65-3fa10f3cda19"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 0s 2ms/step - loss: 0.6744 - accuracy: 0.5333\n",
            "Loss: 0.6744\n",
            "Accuracy: 53.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LlQjNDuVZLk2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q3. Write a python code using Keras to perform Linear regression on randomly generated data"
      ],
      "metadata": {
        "id": "6vuOUJJoZsiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 2: Generating random data\n",
        "np.random.seed(0)\n",
        "X = np.random.rand(200, 1)\n",
        "y = 5 * X + 3 + np.random.randn(200, 1) * 0.1  # Adding some noise\n",
        "\n",
        "# Step 3: Creating a neural network model\n",
        "third_model = Sequential()\n",
        "third_model.add(Dense(1, input_dim=1))\n",
        "\n",
        "# Step 4: Compiling the model\n",
        "third_model.compile(optimizer='sgd', loss='mse')"
      ],
      "metadata": {
        "id": "fOG4BUT2Z1u8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Training the model\n",
        "history = third_model.fit(X, y, epochs=200, verbose=0)"
      ],
      "metadata": {
        "id": "xuQhvQtNacVr"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Plotting the data and the regression line\n",
        "plt.scatter(X, y)\n",
        "plt.plot(X, third_model.predict(X), color='red')\n",
        "plt.xlabel('X')\n",
        "plt.ylabel('y')\n",
        "plt.title('Linear Regression with Keras')\n",
        "plt.show()\n",
        "print(f'Loss: {loss:.4f}')\n",
        "print(f'Accuracy: {accuracy*100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 524
        },
        "id": "borW7kqvad83",
        "outputId": "28cf0b41-2a12-4f67-d632-f2ea5b5814f8"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7/7 [==============================] - 0s 2ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 0.6744\n",
            "Accuracy: 53.33%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NeJRF8Gna3AL"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q4. Use Keras library to create and train a basic RNN for sequence prediction. Use a simple sequence (8, 9, 10, 11, 12, 13) and try to predict the next number in the sequence"
      ],
      "metadata": {
        "id": "_ybgd8SVayYX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense\n",
        "\n",
        "# Generate sample data for the sequence (8, 9, 10, 11, 12, 13)\n",
        "X = np.array([[(i+j)%6 + 8 for j in range(6)] for i in range(100)])\n",
        "y = np.array([(i+6)%6 + 8 for i in range(100)])"
      ],
      "metadata": {
        "id": "Nz8LKUHEbKRN"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ng1ATVJMfsP5",
        "outputId": "2f6c51f3-7869-44f5-d8f5-c8b70e76a69e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 8,  9, 10, 11, 12, 13],\n",
              "       [ 9, 10, 11, 12, 13,  8],\n",
              "       [10, 11, 12, 13,  8,  9],\n",
              "       [11, 12, 13,  8,  9, 10],\n",
              "       [12, 13,  8,  9, 10, 11],\n",
              "       [13,  8,  9, 10, 11, 12],\n",
              "       [ 8,  9, 10, 11, 12, 13],\n",
              "       [ 9, 10, 11, 12, 13,  8],\n",
              "       [10, 11, 12, 13,  8,  9],\n",
              "       [11, 12, 13,  8,  9, 10],\n",
              "       [12, 13,  8,  9, 10, 11],\n",
              "       [13,  8,  9, 10, 11, 12],\n",
              "       [ 8,  9, 10, 11, 12, 13],\n",
              "       [ 9, 10, 11, 12, 13,  8],\n",
              "       [10, 11, 12, 13,  8,  9],\n",
              "       [11, 12, 13,  8,  9, 10],\n",
              "       [12, 13,  8,  9, 10, 11],\n",
              "       [13,  8,  9, 10, 11, 12],\n",
              "       [ 8,  9, 10, 11, 12, 13],\n",
              "       [ 9, 10, 11, 12, 13,  8],\n",
              "       [10, 11, 12, 13,  8,  9],\n",
              "       [11, 12, 13,  8,  9, 10],\n",
              "       [12, 13,  8,  9, 10, 11],\n",
              "       [13,  8,  9, 10, 11, 12],\n",
              "       [ 8,  9, 10, 11, 12, 13],\n",
              "       [ 9, 10, 11, 12, 13,  8],\n",
              "       [10, 11, 12, 13,  8,  9],\n",
              "       [11, 12, 13,  8,  9, 10],\n",
              "       [12, 13,  8,  9, 10, 11],\n",
              "       [13,  8,  9, 10, 11, 12],\n",
              "       [ 8,  9, 10, 11, 12, 13],\n",
              "       [ 9, 10, 11, 12, 13,  8],\n",
              "       [10, 11, 12, 13,  8,  9],\n",
              "       [11, 12, 13,  8,  9, 10],\n",
              "       [12, 13,  8,  9, 10, 11],\n",
              "       [13,  8,  9, 10, 11, 12],\n",
              "       [ 8,  9, 10, 11, 12, 13],\n",
              "       [ 9, 10, 11, 12, 13,  8],\n",
              "       [10, 11, 12, 13,  8,  9],\n",
              "       [11, 12, 13,  8,  9, 10],\n",
              "       [12, 13,  8,  9, 10, 11],\n",
              "       [13,  8,  9, 10, 11, 12],\n",
              "       [ 8,  9, 10, 11, 12, 13],\n",
              "       [ 9, 10, 11, 12, 13,  8],\n",
              "       [10, 11, 12, 13,  8,  9],\n",
              "       [11, 12, 13,  8,  9, 10],\n",
              "       [12, 13,  8,  9, 10, 11],\n",
              "       [13,  8,  9, 10, 11, 12],\n",
              "       [ 8,  9, 10, 11, 12, 13],\n",
              "       [ 9, 10, 11, 12, 13,  8],\n",
              "       [10, 11, 12, 13,  8,  9],\n",
              "       [11, 12, 13,  8,  9, 10],\n",
              "       [12, 13,  8,  9, 10, 11],\n",
              "       [13,  8,  9, 10, 11, 12],\n",
              "       [ 8,  9, 10, 11, 12, 13],\n",
              "       [ 9, 10, 11, 12, 13,  8],\n",
              "       [10, 11, 12, 13,  8,  9],\n",
              "       [11, 12, 13,  8,  9, 10],\n",
              "       [12, 13,  8,  9, 10, 11],\n",
              "       [13,  8,  9, 10, 11, 12],\n",
              "       [ 8,  9, 10, 11, 12, 13],\n",
              "       [ 9, 10, 11, 12, 13,  8],\n",
              "       [10, 11, 12, 13,  8,  9],\n",
              "       [11, 12, 13,  8,  9, 10],\n",
              "       [12, 13,  8,  9, 10, 11],\n",
              "       [13,  8,  9, 10, 11, 12],\n",
              "       [ 8,  9, 10, 11, 12, 13],\n",
              "       [ 9, 10, 11, 12, 13,  8],\n",
              "       [10, 11, 12, 13,  8,  9],\n",
              "       [11, 12, 13,  8,  9, 10],\n",
              "       [12, 13,  8,  9, 10, 11],\n",
              "       [13,  8,  9, 10, 11, 12],\n",
              "       [ 8,  9, 10, 11, 12, 13],\n",
              "       [ 9, 10, 11, 12, 13,  8],\n",
              "       [10, 11, 12, 13,  8,  9],\n",
              "       [11, 12, 13,  8,  9, 10],\n",
              "       [12, 13,  8,  9, 10, 11],\n",
              "       [13,  8,  9, 10, 11, 12],\n",
              "       [ 8,  9, 10, 11, 12, 13],\n",
              "       [ 9, 10, 11, 12, 13,  8],\n",
              "       [10, 11, 12, 13,  8,  9],\n",
              "       [11, 12, 13,  8,  9, 10],\n",
              "       [12, 13,  8,  9, 10, 11],\n",
              "       [13,  8,  9, 10, 11, 12],\n",
              "       [ 8,  9, 10, 11, 12, 13],\n",
              "       [ 9, 10, 11, 12, 13,  8],\n",
              "       [10, 11, 12, 13,  8,  9],\n",
              "       [11, 12, 13,  8,  9, 10],\n",
              "       [12, 13,  8,  9, 10, 11],\n",
              "       [13,  8,  9, 10, 11, 12],\n",
              "       [ 8,  9, 10, 11, 12, 13],\n",
              "       [ 9, 10, 11, 12, 13,  8],\n",
              "       [10, 11, 12, 13,  8,  9],\n",
              "       [11, 12, 13,  8,  9, 10],\n",
              "       [12, 13,  8,  9, 10, 11],\n",
              "       [13,  8,  9, 10, 11, 12],\n",
              "       [ 8,  9, 10, 11, 12, 13],\n",
              "       [ 9, 10, 11, 12, 13,  8],\n",
              "       [10, 11, 12, 13,  8,  9],\n",
              "       [11, 12, 13,  8,  9, 10]])"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c8jM6doVfxY-",
        "outputId": "949a0ebe-ea01-4147-ec0b-a0f570414243"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 8,  9, 10, 11, 12, 13,  8,  9, 10, 11, 12, 13,  8,  9, 10, 11, 12,\n",
              "       13,  8,  9, 10, 11, 12, 13,  8,  9, 10, 11, 12, 13,  8,  9, 10, 11,\n",
              "       12, 13,  8,  9, 10, 11, 12, 13,  8,  9, 10, 11, 12, 13,  8,  9, 10,\n",
              "       11, 12, 13,  8,  9, 10, 11, 12, 13,  8,  9, 10, 11, 12, 13,  8,  9,\n",
              "       10, 11, 12, 13,  8,  9, 10, 11, 12, 13,  8,  9, 10, 11, 12, 13,  8,\n",
              "        9, 10, 11, 12, 13,  8,  9, 10, 11, 12, 13,  8,  9, 10, 11])"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Reshape the data for RNN input (samples, time steps, features)\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))\n",
        "\n",
        "# Define the RNN model\n",
        "model = Sequential([\n",
        "    SimpleRNN(units=32, input_shape=(X.shape[1], X.shape[2]), activation='relu'),\n",
        "    Dense(1)\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mean_squared_error')"
      ],
      "metadata": {
        "id": "m1PZ5Vs4fovv"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train the model\n",
        "model.fit(X, y, epochs=10, batch_size=8)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xepz9ST9cEIA",
        "outputId": "d21de7a4-264c-4309-a11b-dc3768db8b83"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "13/13 [==============================] - 1s 3ms/step - loss: 211.9006\n",
            "Epoch 2/10\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 137.1126\n",
            "Epoch 3/10\n",
            "13/13 [==============================] - 0s 4ms/step - loss: 87.0151\n",
            "Epoch 4/10\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 38.0424\n",
            "Epoch 5/10\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 6.9738\n",
            "Epoch 6/10\n",
            "13/13 [==============================] - 0s 3ms/step - loss: 4.4095\n",
            "Epoch 7/10\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 2.4383\n",
            "Epoch 8/10\n",
            "13/13 [==============================] - 0s 6ms/step - loss: 2.3001\n",
            "Epoch 9/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 1.8127\n",
            "Epoch 10/10\n",
            "13/13 [==============================] - 0s 5ms/step - loss: 1.5560\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7ee645ed8d90>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model\n",
        "test_input = np.array([[(i+j)%6 + 8 for j in range(6)] for i in range(100, 110)])\n",
        "test_input"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZPRIz00cZUq",
        "outputId": "edefd62a-0bd9-4f46-8416-e6ea6e76be2e"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[12, 13,  8,  9, 10, 11],\n",
              "       [13,  8,  9, 10, 11, 12],\n",
              "       [ 8,  9, 10, 11, 12, 13],\n",
              "       [ 9, 10, 11, 12, 13,  8],\n",
              "       [10, 11, 12, 13,  8,  9],\n",
              "       [11, 12, 13,  8,  9, 10],\n",
              "       [12, 13,  8,  9, 10, 11],\n",
              "       [13,  8,  9, 10, 11, 12],\n",
              "       [ 8,  9, 10, 11, 12, 13],\n",
              "       [ 9, 10, 11, 12, 13,  8]])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_input = test_input.reshape((test_input.shape[0], test_input.shape[1], 1))\n",
        "predicted_output = model.predict(test_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q2198nK4f22T",
        "outputId": "3e03e4e5-e2ee-43a1-baee-6dd4b61cff4e"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 154ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the predicted output\n",
        "print(\"Predicted Output:\", round(predicted_output[0, 0]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6dUJcmcQcafh",
        "outputId": "88cf0452-a8be-4f99-ac0b-f5fa37423090"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Output: 12\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "pReQmSQ_f-qX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q5. Create a basic recurrent neural network model for text analysis using Python and TensorFlow. (Input text: \"Anna embrace change; Change is constant\")"
      ],
      "metadata": {
        "id": "KaFz3myegWfc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Sample text data\n",
        "text = \"Anna embrace change; Change is constant\"\n",
        "\n",
        "# Create a vocabulary\n",
        "vocab = sorted(set(text))\n",
        "\n",
        "# Create mappings from characters to indices and vice versa\n",
        "char_to_idx = {char: idx for idx, char in enumerate(vocab)}\n",
        "idx_to_char = np.array(vocab)\n",
        "\n",
        "# Convert text to numerical data\n",
        "text_as_int = np.array([char_to_idx[char] for char in text])\n",
        "\n",
        "# Define the RNN model\n",
        "embedding_dim = 256\n",
        "rnn_units = 1024\n",
        "\n",
        "def build_model(vocab_size, embedding_dim, rnn_units, batch_size):\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Embedding(vocab_size, embedding_dim, batch_input_shape=[batch_size, None]),\n",
        "        tf.keras.layers.SimpleRNN(rnn_units, return_sequences=True, recurrent_initializer='glorot_uniform'),\n",
        "        tf.keras.layers.Dense(vocab_size)\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "model = build_model(\n",
        "    vocab_size=len(vocab),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units,\n",
        "    batch_size=1\n",
        ")\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True))\n",
        "\n",
        "# Define the number of training epochs\n",
        "num_epochs = 100\n",
        "\n",
        "# Reshape input data to include batches of sequences\n",
        "input_text = text_as_int[:-1]\n",
        "target_text = text_as_int[1:]\n",
        "input_text = np.expand_dims(input_text, axis=0)\n",
        "target_text = np.expand_dims(target_text, axis=0)\n",
        "\n",
        "# Train the model\n",
        "model.fit(input_text, target_text, epochs=num_epochs)\n",
        "\n",
        "# Generate text\n",
        "def generate_text(model, start_string, num_generate=1000):\n",
        "    input_eval = [char_to_idx[s] for s in start_string]\n",
        "    input_eval = tf.expand_dims(input_eval, 0)\n",
        "    text_generated = []\n",
        "\n",
        "    model.reset_states()\n",
        "    for _ in range(num_generate):\n",
        "        predictions = model(input_eval)\n",
        "        predictions = tf.squeeze(predictions, 0)\n",
        "        predicted_id = tf.random.categorical(predictions, num_samples=1)[-1, 0].numpy()\n",
        "        input_eval = tf.expand_dims([predicted_id], 0)\n",
        "        text_generated.append(idx_to_char[predicted_id])\n",
        "\n",
        "    return start_string + ''.join(text_generated)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWuCXDPCgqSH",
        "outputId": "d9c4eb6d-1d39-4841-df7e-3488c0c5ece8"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.8520\n",
            "Epoch 2/100\n",
            "1/1 [==============================] - 0s 279ms/step - loss: 2.4944\n",
            "Epoch 3/100\n",
            "1/1 [==============================] - 0s 313ms/step - loss: 2.6893\n",
            "Epoch 4/100\n",
            "1/1 [==============================] - 0s 393ms/step - loss: 1.7680\n",
            "Epoch 5/100\n",
            "1/1 [==============================] - 0s 439ms/step - loss: 2.0991\n",
            "Epoch 6/100\n",
            "1/1 [==============================] - 0s 276ms/step - loss: 2.3474\n",
            "Epoch 7/100\n",
            "1/1 [==============================] - 0s 386ms/step - loss: 1.4994\n",
            "Epoch 8/100\n",
            "1/1 [==============================] - 0s 287ms/step - loss: 1.9954\n",
            "Epoch 9/100\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 1.5187\n",
            "Epoch 10/100\n",
            "1/1 [==============================] - 0s 280ms/step - loss: 1.4623\n",
            "Epoch 11/100\n",
            "1/1 [==============================] - 0s 275ms/step - loss: 0.9968\n",
            "Epoch 12/100\n",
            "1/1 [==============================] - 0s 231ms/step - loss: 1.0089\n",
            "Epoch 13/100\n",
            "1/1 [==============================] - 0s 239ms/step - loss: 0.8394\n",
            "Epoch 14/100\n",
            "1/1 [==============================] - 0s 321ms/step - loss: 0.6987\n",
            "Epoch 15/100\n",
            "1/1 [==============================] - 0s 259ms/step - loss: 0.5147\n",
            "Epoch 16/100\n",
            "1/1 [==============================] - 0s 316ms/step - loss: 0.4612\n",
            "Epoch 17/100\n",
            "1/1 [==============================] - 0s 289ms/step - loss: 0.3783\n",
            "Epoch 18/100\n",
            "1/1 [==============================] - 0s 282ms/step - loss: 0.3223\n",
            "Epoch 19/100\n",
            "1/1 [==============================] - 0s 236ms/step - loss: 0.2977\n",
            "Epoch 20/100\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.2728\n",
            "Epoch 21/100\n",
            "1/1 [==============================] - 0s 209ms/step - loss: 0.2475\n",
            "Epoch 22/100\n",
            "1/1 [==============================] - 0s 219ms/step - loss: 0.2293\n",
            "Epoch 23/100\n",
            "1/1 [==============================] - 0s 229ms/step - loss: 0.2148\n",
            "Epoch 24/100\n",
            "1/1 [==============================] - 0s 212ms/step - loss: 0.2027\n",
            "Epoch 25/100\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.1926\n",
            "Epoch 26/100\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.1840\n",
            "Epoch 27/100\n",
            "1/1 [==============================] - 0s 215ms/step - loss: 0.1764\n",
            "Epoch 28/100\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.1696\n",
            "Epoch 29/100\n",
            "1/1 [==============================] - 0s 165ms/step - loss: 0.1632\n",
            "Epoch 30/100\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.1571\n",
            "Epoch 31/100\n",
            "1/1 [==============================] - 0s 196ms/step - loss: 0.1513\n",
            "Epoch 32/100\n",
            "1/1 [==============================] - 0s 187ms/step - loss: 0.1457\n",
            "Epoch 33/100\n",
            "1/1 [==============================] - 0s 162ms/step - loss: 0.1405\n",
            "Epoch 34/100\n",
            "1/1 [==============================] - 0s 179ms/step - loss: 0.1355\n",
            "Epoch 35/100\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.1309\n",
            "Epoch 36/100\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.1265\n",
            "Epoch 37/100\n",
            "1/1 [==============================] - 0s 139ms/step - loss: 0.1224\n",
            "Epoch 38/100\n",
            "1/1 [==============================] - 0s 160ms/step - loss: 0.1185\n",
            "Epoch 39/100\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.1149\n",
            "Epoch 40/100\n",
            "1/1 [==============================] - 0s 128ms/step - loss: 0.1114\n",
            "Epoch 41/100\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.1081\n",
            "Epoch 42/100\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.1049\n",
            "Epoch 43/100\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.1019\n",
            "Epoch 44/100\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.0989\n",
            "Epoch 45/100\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.0961\n",
            "Epoch 46/100\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.0933\n",
            "Epoch 47/100\n",
            "1/1 [==============================] - 0s 131ms/step - loss: 0.0907\n",
            "Epoch 48/100\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.0881\n",
            "Epoch 49/100\n",
            "1/1 [==============================] - 0s 108ms/step - loss: 0.0855\n",
            "Epoch 50/100\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.0830\n",
            "Epoch 51/100\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.0806\n",
            "Epoch 52/100\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.0783\n",
            "Epoch 53/100\n",
            "1/1 [==============================] - 0s 116ms/step - loss: 0.0759\n",
            "Epoch 54/100\n",
            "1/1 [==============================] - 0s 133ms/step - loss: 0.0737\n",
            "Epoch 55/100\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.0715\n",
            "Epoch 56/100\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.0694\n",
            "Epoch 57/100\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.0673\n",
            "Epoch 58/100\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.0653\n",
            "Epoch 59/100\n",
            "1/1 [==============================] - 0s 130ms/step - loss: 0.0634\n",
            "Epoch 60/100\n",
            "1/1 [==============================] - 0s 115ms/step - loss: 0.0615\n",
            "Epoch 61/100\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0597\n",
            "Epoch 62/100\n",
            "1/1 [==============================] - 0s 170ms/step - loss: 0.0579\n",
            "Epoch 63/100\n",
            "1/1 [==============================] - 0s 109ms/step - loss: 0.0562\n",
            "Epoch 64/100\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.0546\n",
            "Epoch 65/100\n",
            "1/1 [==============================] - 0s 132ms/step - loss: 0.0530\n",
            "Epoch 66/100\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.0515\n",
            "Epoch 67/100\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.0501\n",
            "Epoch 68/100\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0487\n",
            "Epoch 69/100\n",
            "1/1 [==============================] - 0s 145ms/step - loss: 0.0473\n",
            "Epoch 70/100\n",
            "1/1 [==============================] - 0s 149ms/step - loss: 0.0460\n",
            "Epoch 71/100\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0448\n",
            "Epoch 72/100\n",
            "1/1 [==============================] - 0s 138ms/step - loss: 0.0435\n",
            "Epoch 73/100\n",
            "1/1 [==============================] - 0s 118ms/step - loss: 0.0423\n",
            "Epoch 74/100\n",
            "1/1 [==============================] - 0s 111ms/step - loss: 0.0412\n",
            "Epoch 75/100\n",
            "1/1 [==============================] - 0s 125ms/step - loss: 0.0401\n",
            "Epoch 76/100\n",
            "1/1 [==============================] - 0s 122ms/step - loss: 0.0390\n",
            "Epoch 77/100\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.0379\n",
            "Epoch 78/100\n",
            "1/1 [==============================] - 0s 134ms/step - loss: 0.0369\n",
            "Epoch 79/100\n",
            "1/1 [==============================] - 0s 112ms/step - loss: 0.0359\n",
            "Epoch 80/100\n",
            "1/1 [==============================] - 0s 117ms/step - loss: 0.0349\n",
            "Epoch 81/100\n",
            "1/1 [==============================] - 0s 144ms/step - loss: 0.0340\n",
            "Epoch 82/100\n",
            "1/1 [==============================] - 0s 137ms/step - loss: 0.0330\n",
            "Epoch 83/100\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.0321\n",
            "Epoch 84/100\n",
            "1/1 [==============================] - 0s 124ms/step - loss: 0.0312\n",
            "Epoch 85/100\n",
            "1/1 [==============================] - 0s 123ms/step - loss: 0.0304\n",
            "Epoch 86/100\n",
            "1/1 [==============================] - 0s 129ms/step - loss: 0.0295\n",
            "Epoch 87/100\n",
            "1/1 [==============================] - 0s 127ms/step - loss: 0.0287\n",
            "Epoch 88/100\n",
            "1/1 [==============================] - 0s 210ms/step - loss: 0.0278\n",
            "Epoch 89/100\n",
            "1/1 [==============================] - 0s 195ms/step - loss: 0.0270\n",
            "Epoch 90/100\n",
            "1/1 [==============================] - 0s 194ms/step - loss: 0.0263\n",
            "Epoch 91/100\n",
            "1/1 [==============================] - 0s 180ms/step - loss: 0.0255\n",
            "Epoch 92/100\n",
            "1/1 [==============================] - 0s 193ms/step - loss: 0.0247\n",
            "Epoch 93/100\n",
            "1/1 [==============================] - 0s 189ms/step - loss: 0.0240\n",
            "Epoch 94/100\n",
            "1/1 [==============================] - 0s 184ms/step - loss: 0.0233\n",
            "Epoch 95/100\n",
            "1/1 [==============================] - 0s 199ms/step - loss: 0.0226\n",
            "Epoch 96/100\n",
            "1/1 [==============================] - 0s 175ms/step - loss: 0.0219\n",
            "Epoch 97/100\n",
            "1/1 [==============================] - 0s 213ms/step - loss: 0.0212\n",
            "Epoch 98/100\n",
            "1/1 [==============================] - 0s 191ms/step - loss: 0.0206\n",
            "Epoch 99/100\n",
            "1/1 [==============================] - 0s 190ms/step - loss: 0.0199\n",
            "Epoch 100/100\n",
            "1/1 [==============================] - 0s 206ms/step - loss: 0.0193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text\n",
        "generated_text = generate_text(model, start_string=\"change\", num_generate=1000)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a_vyNwGShDlm",
        "outputId": "94ee681c-1943-4c51-f2ab-188606e9677a"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change chC;hrh oma ioccbAnhceigeCsieAncghCgh;nem;e rtanahhnCrooectc;gcgm cnmbtm;as;b;sataannnhti;hge gtncibAncc ihatnnngg;ags;;n bn;bCo AnAnCana;Chnnnroohmnnso t;osomoAnnCCbhthAnnnsnh;AsCate neCCoor;iitstgrnrggsrC;oer;onsanaAnrr;ehCgcmgrr;bmon;osrnnnnoAnnncao irobAnnaninctgcrohennamhbCir AnngstCmt ;abAgemhrc m;nnnbia eo;AnnAngasAnnaCcAois Cg gi;aannnarohmsgm;b tCnnannbtcasegacCccrcacnnerngooimCA ngAnoegcrh;;CC;ora actirnhbsnn as;ecac;rt;nnsagAAntsgbrcsgmtoioammommmhshgaoen ;n ao;Ab mcoecbhnt;istonnmosht  osig;bsbarbhhAChnhmhAotinnnsieACc sAnnnb;ainnn;ggCnc;tsC ictraenoinmgnnnnhbtaCter he;CnCgtssros n ComAnnt;miscAno t hmannr mrnAnrctism;oorigcitbtaocreaamitbhCtAnmtmbAam;nCihgr tboAnnmtttbhsaoaAnisbtahagncAnasthnbhiCCrAn;Cc nnsicbcsnnns cmm cm;iroCnnnhscbaacoCoghbaanetcseii;nnn iabm camhtinhaanso;ocn;hAnnann;anborsr gtgiCmtnonnChrcibnAnmCeAnb; hgtcoa;;bc;gsneoct;oC nnebeghmAicnnnngennAn ACb bannnnnnschonnArahert icCaernnrchg gb;nnnbct;;hrn;;nmsembes;bgc;gegr oAgomh;AnntAAn;btoernshteia nnnne \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "n22OxCZrhT2W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Q6. Create a LSTM model for text analysis using Python and TensorFlow. (Input corpus: \"Anna embrace change; Change is constant\", \"Change is constant\", \"She is a positive thinker\", \"Anna takes life as a challenge\")"
      ],
      "metadata": {
        "id": "vepHVZiAhg2_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Sample larger input text corpus\n",
        "corpus = [\n",
        "    \"Anna embrace change; Change is constant\",\n",
        "    \"Change is constant\",\n",
        "    \"She is a positive thinker\",\n",
        "    \"Anna takes life as a challenge\"\n",
        "]\n",
        "\n",
        "# Prepare tokenizer and word index\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(corpus)\n",
        "word_index = tokenizer.word_index\n",
        "total_words = len(word_index) + 1\n",
        "\n",
        "# Prepare input-output pairs\n",
        "sequences = []\n",
        "for line in corpus:\n",
        "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
        "    for i in range(1, len(token_list)):\n",
        "        n_gram_sequence = token_list[:i+1]\n",
        "        sequences.append(n_gram_sequence)\n",
        "\n",
        "# Pad sequences and create predictors and label\n",
        "max_sequence_len = max([len(seq) for seq in sequences])\n",
        "sequences = pad_sequences(sequences, maxlen=max_sequence_len, padding='pre')\n",
        "x_train, y_train = sequences[:,:-1], sequences[:,-1]\n",
        "\n",
        "# One-hot encode the labels\n",
        "y_train = tf.keras.utils.to_categorical(y_train, num_classes=total_words)\n",
        "\n",
        "# Build LSTM model\n",
        "model = Sequential()\n",
        "model.add(Embedding(total_words, 50, input_length=max_sequence_len-1))  # Embedding layer with 50 dimensions\n",
        "model.add(LSTM(100))\n",
        "model.add(Dense(total_words, activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer=Adam(learning_rate=0.01))\n",
        "\n",
        "# Train the model\n",
        "model.fit(x_train, y_train, epochs=500, verbose=1)\n",
        "\n",
        "# Function to generate text with temperature\n",
        "def generate_text(seed_text, next_words, model, tokenizer, max_sequence_len, temperature=1.0):\n",
        "    output_text = seed_text\n",
        "    for _ in range(next_words):\n",
        "        token_list = tokenizer.texts_to_sequences([output_text])[0]\n",
        "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
        "        predicted_probs = model.predict(token_list, verbose=0)[0]\n",
        "        predicted_probs = np.asarray(predicted_probs).astype('float64')\n",
        "        predicted_probs = np.log(predicted_probs) / temperature\n",
        "        exp_preds = np.exp(predicted_probs)\n",
        "        predicted_probs = exp_preds / np.sum(exp_preds)\n",
        "        predicted_word_index = np.random.choice(range(len(predicted_probs)), p=predicted_probs)\n",
        "        output_word = \"\"\n",
        "        for word, index in tokenizer.word_index.items():\n",
        "            if index == predicted_word_index:\n",
        "                output_word = word\n",
        "                break\n",
        "        output_text += \" \" + output_word\n",
        "    return output_text\n",
        "\n",
        "# Function to generate multiple sentences\n",
        "def generate_sentences(seed_text, num_sentences, words_per_sentence, model, tokenizer, max_sequence_len, temperature=1.0):\n",
        "    sentences = []\n",
        "    for _ in range(num_sentences):\n",
        "        sentence = generate_text(seed_text, words_per_sentence, model, tokenizer, max_sequence_len, temperature)\n",
        "        sentences.append(sentence.strip())\n",
        "    return ', '.join(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwzUQp2chtjw",
        "outputId": "496e942b-c3c0-4a26-eae8-71a531c8e7c9"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "1/1 [==============================] - 3s 3s/step - loss: 2.6379\n",
            "Epoch 2/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.5753\n",
            "Epoch 3/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.4799\n",
            "Epoch 4/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.3226\n",
            "Epoch 5/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.2701\n",
            "Epoch 6/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.0966\n",
            "Epoch 7/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.9786\n",
            "Epoch 8/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.8519\n",
            "Epoch 9/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.6745\n",
            "Epoch 10/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.4934\n",
            "Epoch 11/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3040\n",
            "Epoch 12/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.1444\n",
            "Epoch 13/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.9725\n",
            "Epoch 14/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.8261\n",
            "Epoch 15/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6880\n",
            "Epoch 16/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.5694\n",
            "Epoch 17/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.4814\n",
            "Epoch 18/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.3909\n",
            "Epoch 19/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.2988\n",
            "Epoch 20/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.2606\n",
            "Epoch 21/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.2231\n",
            "Epoch 22/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1820\n",
            "Epoch 23/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1662\n",
            "Epoch 24/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1522\n",
            "Epoch 25/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1336\n",
            "Epoch 26/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1224\n",
            "Epoch 27/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.1148\n",
            "Epoch 28/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.1081\n",
            "Epoch 29/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.1038\n",
            "Epoch 30/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.1004\n",
            "Epoch 31/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0985\n",
            "Epoch 32/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0974\n",
            "Epoch 33/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0957\n",
            "Epoch 34/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0942\n",
            "Epoch 35/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0930\n",
            "Epoch 36/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0919\n",
            "Epoch 37/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0913\n",
            "Epoch 38/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0909\n",
            "Epoch 39/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0904\n",
            "Epoch 40/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0900\n",
            "Epoch 41/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0898\n",
            "Epoch 42/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0894\n",
            "Epoch 43/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0892\n",
            "Epoch 44/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0890\n",
            "Epoch 45/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0888\n",
            "Epoch 46/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0887\n",
            "Epoch 47/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0885\n",
            "Epoch 48/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0883\n",
            "Epoch 49/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0883\n",
            "Epoch 50/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0882\n",
            "Epoch 51/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0881\n",
            "Epoch 52/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0881\n",
            "Epoch 53/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0880\n",
            "Epoch 54/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0880\n",
            "Epoch 55/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0879\n",
            "Epoch 56/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0878\n",
            "Epoch 57/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0878\n",
            "Epoch 58/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0878\n",
            "Epoch 59/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0877\n",
            "Epoch 60/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0877\n",
            "Epoch 61/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0876\n",
            "Epoch 62/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0876\n",
            "Epoch 63/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0876\n",
            "Epoch 64/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0875\n",
            "Epoch 65/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0875\n",
            "Epoch 66/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0875\n",
            "Epoch 67/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0875\n",
            "Epoch 68/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0874\n",
            "Epoch 69/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0874\n",
            "Epoch 70/500\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 0.0874\n",
            "Epoch 71/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0874\n",
            "Epoch 72/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0874\n",
            "Epoch 73/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0874\n",
            "Epoch 74/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0874\n",
            "Epoch 75/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0873\n",
            "Epoch 76/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0873\n",
            "Epoch 77/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0873\n",
            "Epoch 78/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0873\n",
            "Epoch 79/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0873\n",
            "Epoch 80/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0873\n",
            "Epoch 81/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0873\n",
            "Epoch 82/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0873\n",
            "Epoch 83/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0873\n",
            "Epoch 84/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0873\n",
            "Epoch 85/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0873\n",
            "Epoch 86/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0872\n",
            "Epoch 87/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0872\n",
            "Epoch 88/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0872\n",
            "Epoch 89/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0872\n",
            "Epoch 90/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0872\n",
            "Epoch 91/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0872\n",
            "Epoch 92/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0872\n",
            "Epoch 93/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0872\n",
            "Epoch 94/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0872\n",
            "Epoch 95/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0872\n",
            "Epoch 96/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0872\n",
            "Epoch 97/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0872\n",
            "Epoch 98/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0872\n",
            "Epoch 99/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0872\n",
            "Epoch 100/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0872\n",
            "Epoch 101/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0872\n",
            "Epoch 102/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0872\n",
            "Epoch 103/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0871\n",
            "Epoch 104/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0871\n",
            "Epoch 105/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0871\n",
            "Epoch 106/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0871\n",
            "Epoch 107/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0871\n",
            "Epoch 108/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0871\n",
            "Epoch 109/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0871\n",
            "Epoch 110/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0871\n",
            "Epoch 111/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0871\n",
            "Epoch 112/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0871\n",
            "Epoch 113/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0871\n",
            "Epoch 114/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0871\n",
            "Epoch 115/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0871\n",
            "Epoch 116/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0871\n",
            "Epoch 117/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0871\n",
            "Epoch 118/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0871\n",
            "Epoch 119/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0871\n",
            "Epoch 120/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0871\n",
            "Epoch 121/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0871\n",
            "Epoch 122/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0871\n",
            "Epoch 123/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0871\n",
            "Epoch 124/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0871\n",
            "Epoch 125/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0871\n",
            "Epoch 126/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0871\n",
            "Epoch 127/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0871\n",
            "Epoch 128/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0871\n",
            "Epoch 129/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0871\n",
            "Epoch 130/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0870\n",
            "Epoch 131/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0870\n",
            "Epoch 132/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0870\n",
            "Epoch 133/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0870\n",
            "Epoch 134/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0870\n",
            "Epoch 135/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0870\n",
            "Epoch 136/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0870\n",
            "Epoch 137/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0870\n",
            "Epoch 138/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0870\n",
            "Epoch 139/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0870\n",
            "Epoch 140/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0870\n",
            "Epoch 141/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0870\n",
            "Epoch 142/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0870\n",
            "Epoch 143/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0870\n",
            "Epoch 144/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0870\n",
            "Epoch 145/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0870\n",
            "Epoch 146/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0870\n",
            "Epoch 147/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0870\n",
            "Epoch 148/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0870\n",
            "Epoch 149/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0870\n",
            "Epoch 150/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0870\n",
            "Epoch 151/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0870\n",
            "Epoch 152/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0870\n",
            "Epoch 153/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0870\n",
            "Epoch 154/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0870\n",
            "Epoch 155/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0870\n",
            "Epoch 156/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0870\n",
            "Epoch 157/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0870\n",
            "Epoch 158/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0870\n",
            "Epoch 159/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0870\n",
            "Epoch 160/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0870\n",
            "Epoch 161/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0870\n",
            "Epoch 162/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0870\n",
            "Epoch 163/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0870\n",
            "Epoch 164/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0870\n",
            "Epoch 165/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0870\n",
            "Epoch 166/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0870\n",
            "Epoch 167/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0870\n",
            "Epoch 168/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0870\n",
            "Epoch 169/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0870\n",
            "Epoch 170/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0870\n",
            "Epoch 171/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0870\n",
            "Epoch 172/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0869\n",
            "Epoch 173/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0869\n",
            "Epoch 174/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0869\n",
            "Epoch 175/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0869\n",
            "Epoch 176/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0869\n",
            "Epoch 177/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0869\n",
            "Epoch 178/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0869\n",
            "Epoch 179/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0869\n",
            "Epoch 180/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0869\n",
            "Epoch 181/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0869\n",
            "Epoch 182/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0869\n",
            "Epoch 183/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0869\n",
            "Epoch 184/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0869\n",
            "Epoch 185/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0869\n",
            "Epoch 186/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0869\n",
            "Epoch 187/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0869\n",
            "Epoch 188/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0869\n",
            "Epoch 189/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0869\n",
            "Epoch 190/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0869\n",
            "Epoch 191/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0869\n",
            "Epoch 192/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0869\n",
            "Epoch 193/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0869\n",
            "Epoch 194/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0869\n",
            "Epoch 195/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0869\n",
            "Epoch 196/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0869\n",
            "Epoch 197/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0869\n",
            "Epoch 198/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0869\n",
            "Epoch 199/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0869\n",
            "Epoch 200/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0869\n",
            "Epoch 201/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0869\n",
            "Epoch 202/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0869\n",
            "Epoch 203/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0869\n",
            "Epoch 204/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0869\n",
            "Epoch 205/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0869\n",
            "Epoch 206/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0869\n",
            "Epoch 207/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0869\n",
            "Epoch 208/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0869\n",
            "Epoch 209/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0869\n",
            "Epoch 210/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0869\n",
            "Epoch 211/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0869\n",
            "Epoch 212/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0869\n",
            "Epoch 213/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0869\n",
            "Epoch 214/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0869\n",
            "Epoch 215/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0869\n",
            "Epoch 216/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0869\n",
            "Epoch 217/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0869\n",
            "Epoch 218/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0869\n",
            "Epoch 219/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0869\n",
            "Epoch 220/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0869\n",
            "Epoch 221/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0869\n",
            "Epoch 222/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0869\n",
            "Epoch 223/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0869\n",
            "Epoch 224/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0869\n",
            "Epoch 225/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0869\n",
            "Epoch 226/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0869\n",
            "Epoch 227/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0869\n",
            "Epoch 228/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0869\n",
            "Epoch 229/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0869\n",
            "Epoch 230/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0869\n",
            "Epoch 231/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0869\n",
            "Epoch 232/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0869\n",
            "Epoch 233/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0869\n",
            "Epoch 234/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0869\n",
            "Epoch 235/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0869\n",
            "Epoch 236/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0869\n",
            "Epoch 237/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0869\n",
            "Epoch 238/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0869\n",
            "Epoch 239/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0869\n",
            "Epoch 240/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0869\n",
            "Epoch 241/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0869\n",
            "Epoch 242/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0869\n",
            "Epoch 243/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0869\n",
            "Epoch 244/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 245/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 246/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 247/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 248/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0868\n",
            "Epoch 249/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0868\n",
            "Epoch 250/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0868\n",
            "Epoch 251/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0868\n",
            "Epoch 252/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0868\n",
            "Epoch 253/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0868\n",
            "Epoch 254/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0868\n",
            "Epoch 255/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0868\n",
            "Epoch 256/500\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 0.0868\n",
            "Epoch 257/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0868\n",
            "Epoch 258/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0868\n",
            "Epoch 259/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0868\n",
            "Epoch 260/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0868\n",
            "Epoch 261/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0868\n",
            "Epoch 262/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0868\n",
            "Epoch 263/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0868\n",
            "Epoch 264/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0868\n",
            "Epoch 265/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 266/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 267/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0868\n",
            "Epoch 268/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0868\n",
            "Epoch 269/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 270/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0868\n",
            "Epoch 271/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0868\n",
            "Epoch 272/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 273/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 274/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 275/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0868\n",
            "Epoch 276/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 277/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 278/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0868\n",
            "Epoch 279/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 280/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 281/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0868\n",
            "Epoch 282/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0868\n",
            "Epoch 283/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0868\n",
            "Epoch 284/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 285/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 286/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0868\n",
            "Epoch 287/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 288/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0868\n",
            "Epoch 289/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 290/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 291/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 292/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 293/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0868\n",
            "Epoch 294/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0868\n",
            "Epoch 295/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0868\n",
            "Epoch 296/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0868\n",
            "Epoch 297/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0868\n",
            "Epoch 298/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0868\n",
            "Epoch 299/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 300/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0868\n",
            "Epoch 301/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0868\n",
            "Epoch 302/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0868\n",
            "Epoch 303/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0868\n",
            "Epoch 304/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 305/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 306/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 307/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0868\n",
            "Epoch 308/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0868\n",
            "Epoch 309/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 310/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0868\n",
            "Epoch 311/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0868\n",
            "Epoch 312/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0868\n",
            "Epoch 313/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0868\n",
            "Epoch 314/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0868\n",
            "Epoch 315/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 316/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0868\n",
            "Epoch 317/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0868\n",
            "Epoch 318/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0868\n",
            "Epoch 319/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0868\n",
            "Epoch 320/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0868\n",
            "Epoch 321/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0868\n",
            "Epoch 322/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0868\n",
            "Epoch 323/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0868\n",
            "Epoch 324/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0868\n",
            "Epoch 325/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0868\n",
            "Epoch 326/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 327/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0868\n",
            "Epoch 328/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0868\n",
            "Epoch 329/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0868\n",
            "Epoch 330/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0868\n",
            "Epoch 331/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0868\n",
            "Epoch 332/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0868\n",
            "Epoch 333/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0868\n",
            "Epoch 334/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0868\n",
            "Epoch 335/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0868\n",
            "Epoch 336/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0868\n",
            "Epoch 337/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0868\n",
            "Epoch 338/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 339/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 340/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 341/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0868\n",
            "Epoch 342/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0868\n",
            "Epoch 343/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0868\n",
            "Epoch 344/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 345/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 346/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 347/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 348/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0868\n",
            "Epoch 349/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0868\n",
            "Epoch 350/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0868\n",
            "Epoch 351/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0868\n",
            "Epoch 352/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 353/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0868\n",
            "Epoch 354/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 355/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 356/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0868\n",
            "Epoch 357/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0868\n",
            "Epoch 358/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 359/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 360/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0868\n",
            "Epoch 361/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 362/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0868\n",
            "Epoch 363/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 364/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0868\n",
            "Epoch 365/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 366/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0868\n",
            "Epoch 367/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0868\n",
            "Epoch 368/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 369/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0868\n",
            "Epoch 370/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0868\n",
            "Epoch 371/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 372/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0868\n",
            "Epoch 373/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0868\n",
            "Epoch 374/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0868\n",
            "Epoch 375/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 376/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0868\n",
            "Epoch 377/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0868\n",
            "Epoch 378/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 379/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 380/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 381/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 382/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 383/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0868\n",
            "Epoch 384/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 385/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0868\n",
            "Epoch 386/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0868\n",
            "Epoch 387/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 388/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0868\n",
            "Epoch 389/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 390/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0868\n",
            "Epoch 391/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0868\n",
            "Epoch 392/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0868\n",
            "Epoch 393/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0868\n",
            "Epoch 394/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0868\n",
            "Epoch 395/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0868\n",
            "Epoch 396/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0868\n",
            "Epoch 397/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0868\n",
            "Epoch 398/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0868\n",
            "Epoch 399/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0868\n",
            "Epoch 400/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0868\n",
            "Epoch 401/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0868\n",
            "Epoch 402/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 403/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 404/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 405/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 406/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0868\n",
            "Epoch 407/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 408/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 409/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0868\n",
            "Epoch 410/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0868\n",
            "Epoch 411/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0868\n",
            "Epoch 412/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0867\n",
            "Epoch 413/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0867\n",
            "Epoch 414/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0867\n",
            "Epoch 415/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0867\n",
            "Epoch 416/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0867\n",
            "Epoch 417/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0867\n",
            "Epoch 418/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0867\n",
            "Epoch 419/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0867\n",
            "Epoch 420/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0867\n",
            "Epoch 421/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0867\n",
            "Epoch 422/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0867\n",
            "Epoch 423/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0867\n",
            "Epoch 424/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0867\n",
            "Epoch 425/500\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 0.0867\n",
            "Epoch 426/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0867\n",
            "Epoch 427/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0867\n",
            "Epoch 428/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0867\n",
            "Epoch 429/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0867\n",
            "Epoch 430/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0867\n",
            "Epoch 431/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0867\n",
            "Epoch 432/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0867\n",
            "Epoch 433/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0867\n",
            "Epoch 434/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0867\n",
            "Epoch 435/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0867\n",
            "Epoch 436/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0867\n",
            "Epoch 437/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0867\n",
            "Epoch 438/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0867\n",
            "Epoch 439/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0867\n",
            "Epoch 440/500\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 0.0867\n",
            "Epoch 441/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0867\n",
            "Epoch 442/500\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 0.0867\n",
            "Epoch 443/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0867\n",
            "Epoch 444/500\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 0.0867\n",
            "Epoch 445/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0867\n",
            "Epoch 446/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0867\n",
            "Epoch 447/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0867\n",
            "Epoch 448/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0867\n",
            "Epoch 449/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0867\n",
            "Epoch 450/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0867\n",
            "Epoch 451/500\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 0.0867\n",
            "Epoch 452/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0867\n",
            "Epoch 453/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0867\n",
            "Epoch 454/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0867\n",
            "Epoch 455/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0867\n",
            "Epoch 456/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0867\n",
            "Epoch 457/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0867\n",
            "Epoch 458/500\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 0.0867\n",
            "Epoch 459/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0867\n",
            "Epoch 460/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0867\n",
            "Epoch 461/500\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 0.0867\n",
            "Epoch 462/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0867\n",
            "Epoch 463/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0867\n",
            "Epoch 464/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0867\n",
            "Epoch 465/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0867\n",
            "Epoch 466/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0867\n",
            "Epoch 467/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0867\n",
            "Epoch 468/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0867\n",
            "Epoch 469/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0867\n",
            "Epoch 470/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0867\n",
            "Epoch 471/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0867\n",
            "Epoch 472/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0867\n",
            "Epoch 473/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0867\n",
            "Epoch 474/500\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 0.0867\n",
            "Epoch 475/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0867\n",
            "Epoch 476/500\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 0.0867\n",
            "Epoch 477/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0867\n",
            "Epoch 478/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0867\n",
            "Epoch 479/500\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 0.0867\n",
            "Epoch 480/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0867\n",
            "Epoch 481/500\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 0.0867\n",
            "Epoch 482/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0867\n",
            "Epoch 483/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0867\n",
            "Epoch 484/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0867\n",
            "Epoch 485/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0867\n",
            "Epoch 486/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0867\n",
            "Epoch 487/500\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 0.0867\n",
            "Epoch 488/500\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 0.0867\n",
            "Epoch 489/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0867\n",
            "Epoch 490/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0867\n",
            "Epoch 491/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0867\n",
            "Epoch 492/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0867\n",
            "Epoch 493/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0867\n",
            "Epoch 494/500\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 0.0867\n",
            "Epoch 495/500\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 0.0867\n",
            "Epoch 496/500\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 0.0867\n",
            "Epoch 497/500\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 0.0867\n",
            "Epoch 498/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0867\n",
            "Epoch 499/500\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 0.0867\n",
            "Epoch 500/500\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 0.0867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate multiple sentences\n",
        "seed_text = \"change\"\n",
        "num_sentences = 5\n",
        "words_per_sentence = 3\n",
        "temperature = 1.0  # Adjust temperature for more or less randomness\n",
        "generated_text = generate_sentences(seed_text, num_sentences, words_per_sentence, model, tokenizer, max_sequence_len, temperature)\n",
        "print(generated_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kvC-NjziA6d",
        "outputId": "380759c6-a50f-4df4-eea6-00fa1e2b6814"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "change is constant constant, change is constant constant, change is constant constant, change is constant constant, change is constant constant\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vv1MxtcPiIw4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}